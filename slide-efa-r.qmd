
---
title: "Análise Fatorial Exploratória"
subtitle: "Aplicação no R"
format: 
  revealjs:
      logo: img/brasao1_horizontal_cor_300dpi.png
      theme: simple
      css: logo.css
      scrollable: true
progress: true
slide-number: true
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: false
source("./_common.R")
```

```{r}
#| label: setup
library(tidyverse)
library(janitor)
library(scales)
library(careless)
library(gt)
library(EGAnet)
library(lavaan)
library(MVN)
library(psych)
library(ggcorrplot)
```

```{r}
cb_racismo_moderno <- read_csv("data/code_book_escala_racismo_moderno.csv")
df <- read_csv("data/dados_racismo_moderno.csv")
```

## Escala de Racismo Moderno {.smaller}

A Escala de Racismo Moderno foi desenvolvida por McConahay (1983) e adaptada para a Espanha por Navas (1998). Essa versão foi utilizada por Santos et al. (2006) para adaptar o instrumento ao Brasil, incorporando itens mais alinhados à cultura brasileira. A versão brasileira da escala é composta por 14 itens agrupados em dois fatores: negação do preconceito (ex.: “Eles têm conseguido mais do que merecem”) e afirmação de diferenças (ex.: “Eles são mais habilidosos em trabalhos manuais”). As pontuações variam de 1 (discordo totalmente) a 7 (concordo totalmente), onde pontuações mais altas indicam um nível mais elevado de racismo.

## Escala de Racismo Moderno {.smaller}

```{r}
cb_racismo_moderno |> 
  gt() |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  cols_align(
    columns = Variável,
    align = "center" 
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  ) |> 
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_column_labels(columns = c(Variável, Item, Fator))
    ) |> 
  tab_options(
    table.font.size = "18px"
  )
```

## Obtenção dos dados

Utilize o código abaixo para baixar o banco de dados e salvá-lo no objeto `df`

```{r}
#| echo: true
#| eval: false
df <- read_csv("https://raw.githubusercontent.com/pablo-huascar/pesquisa_quanti_psi_ufc/refs/heads/main/data/dados_racismo_moderno.csv")
```

## Uma olhada nos dados {.smaller}

```{r}
#| tbl-cap: Uma amostra aleatória de dez casos do banco de dados 
#| tbl-cap-location: bottom
set.seed(123)
df |> 
  slice_sample(n = 10) |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |> 
  fmt_number(
    columns = renda_per_capta, decimals = 2
    ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "18px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Participantes

```{r}
#| label: descritivos
descritivos <- df |> 
  select(sexo, cor_raca, estado_civil) |> 
  pivot_longer(cols = everything()) |> 
  count(name, value) |> 
  mutate(
    prop = n/sum(n) |> round(1), 
    prop = percent_format(big.mark = ".", decimal.mark = ",")(prop),
    .by = name
  ) |> 
  arrange(factor(name, levels = c("sexo", "estado_civil", "cor_raca")), n)

feminino_prop <- descritivos$prop[descritivos$value == "Feminino"]
pardo_prop <- descritivos$prop[descritivos$value == "Parda"]
idade_range <- range(df$idade)
idade_media <- mean(df$idade) |> round(2) |> format(decimal.mark = ",")
idade_dp <- sd(df$idade) |> round(2) |> format(decimal.mark = ",")
estado_civil_prop <- descritivos$prop[descritivos$value == "Solteiro(a)"]
renda_media <- mean(df$renda_per_capta, na.rm = T) |> round(2) |> 
  format(decimal.mark = ",")
renda_dp <- sd(df$renda_per_capta, na.rm = T) |> round(2) |> 
  format(decimal.mark = ",")
```

Participaram do estudo `r nrow(df)` estudantes universitários. A maior parte era do sexo feminino (`r feminino_prop`) e se declarou como pardo (`r pardo_prop`). A idade variou entre `r idade_range[1]` e `r idade_range[2]` anos (M = `r idade_media`, DP = `r idade_dp`). Em relação ao estado civil, `r estado_civil_prop` afirmaram ser solteiros. A renda familiar per capita média foi de `r renda_media` (DP = `r renda_dp`)

## Pacotes

Carregue os pacotes abaixo:

```{r}
#| echo: true
#| eval: false
library(tidyverse)
library(careless)
library(MVN)
library(EGAnet)
library(psych)
library(lavaan)
```

# Inspeção de dados <br> (Data screening)

## Manipulação dos dados

```{r}
#| echo: true
escala_de_racismo <- df |>
  select(r1:r14)  # <1>
```

1.  Selecionar as variáveis da escala

## Escala de resposta e valores ausentes

::: panel-tabset
### Código

```{r}
#| echo: true
resposta_e_ausentes <- escala_de_racismo |> 
  summarise(
    n = n(),
    across(r1:r14, list(
      Minimo = min,
      Máximo = max,
      Ausentes = \(x) sum(is.na(x))
    )), 
  ) |> 
  pivot_longer(
    cols = starts_with("r"),
    names_to = c("Variável", ".value"),
    names_sep = "_"
  ) |> 
  relocate(n, .after = Máximo)
```

### Resultado

```{r}
resposta_e_ausentes |> 
  print(n = Inf)
```
:::

## Escala de resposta e valores ausentes (`describe()`)

```{r}
#| echo: true
escala_de_racismo |> 
  describe()
```

## Respostas descuidadas {.smaller}

::: panel-tabset
### `longstring()`

```{r}
#| echo: true
respostas_descuidadas <- longstring(escala_de_racismo, avg = T) |> 
  as_tibble() |> 
  mutate(
    id = 1:n(), .before = 1
  ) |> 
  arrange(desc(longstr)) 

respostas_descuidadas
```

### Filtragem dos casos

```{r}
#| echo: true
ids <- respostas_descuidadas |> 
  filter(longstr == 14) |> 
  select(id) |> 
  pull()

casos <- escala_de_racismo |>
  mutate(
    id = 1:n(), .before = 1
  ) |> 
  filter(id %in% ids) 
```

### Avaliação dos casos

```{r}
#| echo: true
casos |> 
  print(n = Inf)
```
:::

# Avaliação preliminar

## Normalidade dos dados {.smaller}

::: panel-tabset
### Teste

```{r}
#| echo: true
resultado_normalidade <- mvn(
  escala_de_racismo, 
  mvnTest = "mardia",
  univariateTest = "SW"
)
```

### Assimetria e curtose

```{r}
#| echo: true
resultado_normalidade$Descriptives |> 
  as_tibble() |> 
  print(n = Inf)
```

### Normalidade univariada

```{r}
#| echo: true
resultado_normalidade$univariateNormality
```

### Normalidade multivariada

```{r}
#| echo: true
resultado_normalidade$multivariateNormality
```
:::

## Correlação entre os itens

```{r}
#| echo: true
#| output-location: slide
escala_de_racismo |> 
  polychoric.matrix() |> 
  ggcorrplot(
    hc.order = F,
    type = "lower",
    lab = TRUE,
    lab_size = 2.5
  )
```

## Fatorabilidade da Matriz de Dados

::: panel-tabset
### KMO

```{r}
#| echo: true
escala_de_racismo |> 
  polychoric.matrix() |> 
  KMO()
```

### Teste de esfericidade de Bartlett

```{r}
#| echo: true
escala_de_racismo |> 
  polychoric.matrix() |> 
  cortest.bartlett(n = 322)
```
:::

# Retenção de fatores

## Análise paralela {.smaller}

```{r}
#| echo: true
analise_paralela <- escala_de_racismo |> 
  polychoric.matrix() |> 
  fa.parallel(
    n.obs = 322, fm = "pa", 
    plot = F
  )

analise_paralela
```

## Análise paralela {.smaller}

```{r}
tibble(
  "Autovalores para os daos reais" = analise_paralela$fa.values,
  "Autovalores para os dados simulados" = analise_paralela$fa.sim
) |> 
  print(n = Inf)
```

## MAP {.smaller}

```{r}
#| echo: true
escala_de_racismo |> 
  polychoric.matrix() |> 
  vss(n.obs = 322, plot = F) 
```

# Estimadores JASP

## **Minimum Residual (Mínimos Resíduos)** {.smaller}

-   **O que faz**: Também conhecido como **ULS (Unweighted Least Squares)**, minimiza a soma dos quadrados dos resíduos entre a matriz observada e a matriz modelada, **sem ponderar** os elementos.
-   **Quando usar**:
    -   Dados contínuos ou ordinais com violação de normalidade.
    -   Amostras pequenas (é menos exigente que ML).
-   **Suposições**: Não assume normalidade, mas requer homocedasticidade.
-   **Comparação com lavaan**: Equivalente ao `estimator = "ULS"` no lavaan.


## **Maximum Likelihood (Máxima Verossimilhança)** {.smaller}

-   **O que faz**: Estima parâmetros que maximizam a probabilidade dos dados observados, assumindo normalidade multivariada.
-   **Quando usar**:
    -   Dados contínuos e normais.
    -   Quando se deseja testes de ajuste (ex.: χ²) e intervalos de confiança.
-   **Suposições**: Normalidade multivariada e tamanho amostral adequado (n \> 200).
-   **Comparação com lavaan**: Equivalente ao `estimator = "ML"`. No JASP, não há variantes robustas por padrão.


## **Principal Axis Factoring (PAF - Fatoração por Eixos Principais)** {.smaller}

-   **O que faz**: Método de extração que estima **comunalidades** (variância compartilhada entre variáveis) iterativamente, usando correlações parciais.
-   **Quando usar**:
    -   Dados não normais.
    -   Quando o objetivo é identificar a estrutura latente sem assumir normalidade.
-   **Suposições**: Não assume normalidade, mas requer que as comunalidades sejam razoavelmente altas.
-   **Diferença do PCA**: O PAF é um método de **análise fatorial** (modela variância comum), enquanto o PCA é uma técnica de redução de dados (modela variância total).

## **Ordinary Least Squares (Mínimos Quadrados Ordinários - OLS)** {.smaller}

-   **O que faz**: Similar ao *Minimum Residual*, mas focado em minimizar resíduos sem ajustes. Não confundir com regressão OLS.
-   **Quando usar**: Casos simples onde a prioridade é simplicidade computacional.
-   **Suposições**: Mesmas do *Minimum Residual*.
-   **Comparação com lavaan**: Praticamente idêntico ao `estimator = "ULS"`.


## **Weighted Least Squares (WLS - Mínimos Quadrados Ponderados)** {.smaller}

-   **O que faz**: Pondera os resíduos pela inversa da matriz de covariância assintótica. Adequado para dados ordinais.
-   **Quando usar**:
    -   Dados ordinais (ex.: escalas Likert).
    -   Quando há não normalidade extrema.
-   **Suposições**: Requer amostras grandes (n \> 1.000) para estabilidade.
-   **Comparação com lavaan**: Equivalente ao `estimator = "WLSMV"` se combinado com correções robustas.


## **Generalized Least Squares (GLS - Mínimos Quadrados Generalizados)** {.smaller}

-   **O que faz**: Versão generalizada do OLS que pondera os resíduos pela matriz de covariância residual.
-   **Quando usar**: Dados contínuos com heterocedasticidade conhecida.
-   **Suposições**: Normalidade e matriz de covariância bem especificada.
-   **Comparação com lavaan**: Similar ao `estimator = "GLS"`.


## **Minimum Chi-Square (Mínimo Qui-Quadrado)** {.smaller}

-   **O que faz**: Minimiza a discrepância do qui-quadrado entre a matriz observada e a modelada.
-   **Quando usar**:
    -   Dados categóricos (ex.: tabelas de contingência).
    -   Quando se busca compatibilidade com métodos de triagem de modelos.
-   **Suposições**: Tabelas de contingência bem preenchidas (frequências \> 5).


## **Minimum Rank (Mínimo Posto)** {.smaller}

-   **O que faz**: Método que minimiza o posto (rank) da matriz de covariância residual, buscando a estrutura mais parcimoniosa.
-   **Quando usar**:
    -   Para explorar o número mínimo de fatores necessários.
    -   Em dados com alta colinearidade.
-   **Suposições**: Adequado para dados de alta dimensionalidade.

## **Tabela Comparativa: Quando Usar Cada Estimador no JASP** {.smaller}

| **Estimador** | **Dados Contínuos** | **Dados Ordinais** | **Normalidade** | **Amostra Pequena** | **Uso Típico** |
|------------|------------|------------|------------|------------|-------------|
| **Minimum Residual** | Sim | Sim | Não requer | Sim | Dados não normais ou pequenas amostras |
| **Maximum Likelihood** | Sim | Não | Requer | Não (n \> 200) | Dados normais com teste de ajuste |
| **Principal Axis Factoring** | Sim | Sim | Não requer | Sim | Exploração de estrutura latente |
| **Weighted Least Squares** | Não | Sim | Não requer | Não (n \> 1.000) | Dados ordinais ou não normais |
| **Generalized LS** | Sim | Não | Requer | Não | Dados contínuos com heterocedasticidade |
| **Minimum Chi-Square** | Não | Sim (categóricos) | Não requer | Não | Tabelas de contingência |
| **Minimum Rank** | Sim | Sim | Não requer | Sim | Redução de dimensionalidade |

## **Exemplo Prático no JASP** {.smaller}

1.  **Dados normais e contínuos**:
    -   Escolha *Maximum Likelihood* para obter testes de ajuste e cargas fatoriais precisas.
2.  **Dados ordinais (Likert)**:
    -   Use *Weighted Least Squares* (WLS) ou *Principal Axis Factoring* (PAF).
3.  **Amostra pequena e não normal**:
    -   Prefira *Minimum Residual* ou *Minimum Rank*.

# Estimadores lavaan: básicos {.smaller}

## **a) ML (Maximum Likelihood)** {.smaller}
- **Funcionamento:** Baseia-se na maximização da função de verossimilhança para estimar parâmetros. Assume normalidade multivariada.
- **Vantagens:**
  - Eficiente para grandes amostras e dados normais.
  - Suporta dados incompletos via *Full Information Maximum Likelihood* (FIML).
- **Limitações:**
  - Sensível a violações de normalidade (viés nos erros padrão e teste de ajuste χ²).
  - Requer grandes amostras para estabilidade.

## **b) GLS (Generalized Least Squares)** {.smaller}
- **Funcionamento:** Minimiza a diferença entre a matriz de covariância observada e a modelada, ponderando pelos resíduos.
- **Uso Ideal:** Dados contínuos e normais, mas com heterocedasticidade conhecida.
- **Limitação:** Não funciona com dados ordinais ou incompletos.

## **c) WLS/DWLS/ULS** {.smaller}
- **WLS (Weighted Least Squares):** Usa toda a matriz de peso (inversa da matriz de covariância assintótica). Adequado para dados ordinais, mas exige amostras grandes (n > 1.000) para estabilidade.
- **DWLS (Diagonally Weighted LS):** Usa apenas a diagonal da matriz de peso. Mais estável que WLS para amostras menores (n > 200).
- **ULS (Unweighted LS):** Não usa ponderação. Rápido, mas menos preciso.
- **Recomendação:** 
  - Para dados ordinais (ex.: escalas Likert), **DWLS** ou **WLSMV** (variante robusta) são preferidos ([Li, 2016](https://link.springer.com/article/10.3758/s13428-015-0619-7)).

# Estimadores lavaan: robustos 

## **a) MLM, MLR, MLMV (Robust ML)** {.smaller}
- **MLM (Satorra-Bentler):**
  - **Correção:** Ajusta o teste χ² e os erros padrão usando a correção de escala de Satorra-Bentler.
  - **Uso:** Dados contínuos não normais e completos.
  - **Exemplo:** Se a curtose for moderada, o MLM reduz falsos positivos no teste de ajuste.

- **MLR (Yuan-Bentler):**
  - **Correção:** Combina erros padrão robustos (Huber-White) e teste χ² escalonado (Yuan-Bentler).
  - **Vantagem:** Funciona com dados **incompletos** (FIML robusto).
  - **Recomendação:** Padrão para dados contínuos não normais com *missing values* ([Enders, 2010](https://psycnet.apa.org/record/2010-03935-007)).

- **MLMV e MLMVS:** Ajustam média e variância do teste χ². Úteis para amostras pequenas (< 200), onde MLM pode ser conservativo.

## **b) WLSMV (Robust DWLS)** {.smaller}
- **Funcionamento:** 
  1. Usa a diagonal da matriz de peso para estimação (DWLS).
  2. Usa a matriz completa para corrigir erros padrão e estatísticas de teste.
- **Vantagens:**
  - Adequado para dados ordinais e pequenas amostras (n > 100).
  - Menos sensível a violações de normalidade.
- **Exemplo Prático:** Modelagem de questionários com escalas Likert ([Finney & DiStefano, 2013](https://psycnet.apa.org/record/2012-28125-008)).

## **3. Comparação Detalhada dos Estimadores** {.smaller}

| **Estimador** | **Dados Suportados**       | **Robustez**                     | **Uso Típico**                          | **Exemplo lavaan**              |
|---------------|----------------------------|-----------------------------------|------------------------------------------|----------------------------------|
| **ML**        | Contínuos normais          | Não                               | Dados completos ou FIML                  | `estimator = "ML"`              |
| **MLR**       | Contínuos não normais      | Sim (Yuan-Bentler)                | Dados com *missing* e não normalidade    | `estimator = "MLR"`             |
| **WLSMV**     | Ordinais/categóricos       | Sim (correção completa)           | Escalas Likert (ex.: CFA)                | `estimator = "WLSMV"`           |
| **MLM**       | Contínuos não normais      | Sim (Satorra-Bentler)             | Dados completos e não normais            | `estimator = "MLM"`             |
| **PML**       | Dados incompletos          | Parcial (estimação pareada)       | *Missing* não monotônico                 | `estimator = "PML"`             |

## **Recomendações Para Dados Contínuos** {.smaller}
- **Normalidade e dados completos:** Use **ML**.
- **Não normalidade ou *missing values*:** Prefira **MLR** (mais flexível e robusto).
- **Amostras pequenas (< 200):** Use **MLMVS** ou **MLMV** para correção dupla (média e variância).

## **Recomendações Para Dados Ordinais (Likert)** {.smaller}
- **Padrão do lavaan:** **WLSMV**, pois combina eficiência e robustez.
- **Amostras muito pequenas (n < 100):** Evite WLS/DWLS; use **Bayesian SEM** ou simplifique o modelo.

## **c) Recomendações Para Dados com *Missing Values*** {.smaller}
- **Contínuos:** **MLR** com FIML.
- **Ordinais:** **PML** (Pairwise ML) ou **WLSMV** com imputação múltipla.


## **7. Resumo Visual: Fluxograma de Escolha do Estimador**
```
Dados Contínuos? 
  ├─ Sim → Normais? 
  │   ├─ Sim → ML (ou MLR para missing) 
  │   └─ Não → MLR ou MLM 
  └─ Não (Ordinais/Categóricos) → WLSMV ou ULSMV
```

## `efa()`

-   `ordered = T` implica em "WLSMV":

    -   `estimator = "DWLS"`
    -   `se = "robust.sem"`
    -   `test = "scaled.shifted"`

```{r}
#| echo: true
resultado_afe <- efa(
  data = escala_de_racismo,
  ordered = T,
  nfactors = 2,
  rotation = "oblimin",
)
```

## Resultados {.smaller}

```{r}
#| echo: true
summary(resultado_afe, cutoff = 0.4)
```


## Referências {.smaller}

McConahay, J. B. (1983). Modern racism and modern discrimination: The effects of race, racial attitudes, and context on simulated hiring decisions. *Personality and Social Psychology Bulletin, 9*(4), 551-558. https://doi.org/10.1177/0146167283094004

Navas MS. (1998). New measurement instruments for the new racism. *International Journal of Social Psychology, 13*(2), 233-239. https://doi.org/10.1174/021347498760350731

Santos, W. S. dos ., Gouveia, V. V., Navas, M. S., Pimentel, C. E., & Gusmão, E. É. da S. (2006). Escala de racismo moderno: adaptação ao contexto brasileiro. *Psicologia Em Estudo, 11*(3), 637–645. https://doi.org/10.1590/S1413-73722006000300020
