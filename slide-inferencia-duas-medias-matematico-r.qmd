---
title: "Inferência"
subtitle: "Comparar duas médias independentes: aplicação do modelo matemático no R"
format: 
  revealjs:
      logo: img/brasao1_horizontal_cor_300dpi.png
      theme: simple
      css: logo.css
progress: true
slide-number: true
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: false
source("./_common.R")
```

```{r}
#| label: setup
library(conflicted)
library(tidyverse)
library(truncnorm)
library(gt)
library(rstatix)
library(magick)
conflicts_prefer(dplyr::lag)
conflicts_prefer(dplyr::filter)
```

```{r}
# Simulação de dados para pesquisa fictícia
set.seed(123)

notas_leitores <- rtruncnorm(
  n = 50,
  a = 0,     
  b = 10,     
  mean = 8,   
  sd = 1.2    
)

notas_nao_leitores <- rtruncnorm(
  n = 48,
  a = 0,
  b = 10,
  mean = 6.8,
  sd = 1.3
)

nota <- c(notas_leitores, notas_nao_leitores)

grupo <- c(rep("leitor", 50), (rep("não leitor", 48)))

pesquisa_fic <- tibble(
  nota = nota,
  grupo = as_factor(grupo)
)

pesquisa_fic <- pesquisa_fic |> 
  mutate(
    nota = round(nota, 1)
  )
```

```{r}
#| eval: false
pesquisa_fic |> 
  summarise(
    m = mean(nota),
    .by = grupo
  )

pesquisa_fic |> 
  group_by(grupo) |> 
  shapiro_test(nota)

pesquisa_fic |> 
  levene_test(formula = nota ~ grupo)

pesquisa_fic |> 
  t_test(nota ~ grupo, var.equal = T, 
         alternative = "two.sided", detailed = T)

pesquisa_fic |> 
  write_csv("data/pesquisa-fic-teste-t.csv")
```

# Bancos de dados utilizados

##  {background-image="img/mtcars.png" background-size="contain"}

## `mtcars` {.smaller}

::: {style="font-size: 18pt;"}
Os dados foram extraídos da revista Motor Trend US de 1974 e abrangem o consumo de combustível e 10 aspectos do design e desempenho de automóveis para 32 carros (modelos de 1973-74)

-   Formato: Um banco de dados com `r nrow(mtcars)` observações e `r ncol(mtcars)` variáveis.
    -   `mpg`: milhas/galão (km/l)
    -   `cyl`: número de cilindros
    -   `disp`: cilindrada (polegadas cúbicas)
    -   `hp`: potência bruta (cavalos de potência)
    -   `drat`: relação de transmissão do eixo traseiro
    -   `wt`: peso (1000 lbs)
    -   `qsec`: tempo para 1/4 de milha
    -   `vs`: motor (0 = em forma de V, 1 = reto)
    -   `am`: transmissão (0 = automática, 1 = manual)
    -   `gear`: número de marchas para frente
    -   `carb`: número de carburadores
:::

## Uma olhada em `mtcars`

```{r}
#| label: tbl-mtcars
#| tbl-cap: Uma amostra aleatória de dez casos do banco de dados `mtcars`
#| tbl-cap-location: bottom 
set.seed(123)

mtcars |> 
  rownames_to_column(var = "Modelo") |> 
  as_tibble() |> 
  select(Modelo, wt, mpg, cyl) |> 
  slice_sample(n = 10) |> 
  gt() |> 
  fmt_number(
    decimals = 1
  ) |> 
  cols_align(
    align = "center"  
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
    )
```

## Pacotes

Carregue os pacotes abaixo:

```{r}
#| echo: true
#| eval: false
library(tidyverse)
library(rstatix)
```

# Teste t para amostras independentes {style="font-size: 22pt;"}

## Pesquisa fictícia {.smaller}

-   Pergunta de partida:
    -   Qual é o efeito do hábito de ler dos textos antes das aulas sobre as médias de avaliação de discentes do curso de psicologia?
        -   Grupo de leitores X Grupo de não leitores

![](img/pesquisa-fic-teste-t.png){fig-align="center"}

## Hipóteses {.smaller}

-   Hipótese nula ($H_0$ - é a hipótese que tentaremos rejeitar): não há diferença entre as médias das notas dos dois grupos
    -   $H_0: \mu_{leitores} = \mu_{não-leitores}$[^1]
    -   $H_0: \mu_{leitores} - \mu_{não-leitores} = 0$
-   Hipótese alternativa ($H_1$): há uma diferença entre as médias das notas dos dois grupos
    -   $H_1: \mu_{leitores} \neq \mu_{não-leitores}$
    -   $H_1: \mu_{leitores} - \mu_{não-leitores} \neq 0$

[^1]: Onde $\mu_{leitores}$ é a média da população de alunos que leem e $\mu_{não-leitores}$ é a média da população de alunos que não leem

## O que os dados da pesquisa fictícia sugerem?

```{r}
#| out-width: "70%"
pesquisa_fic |> 
  ggplot(
    aes(x = grupo, y = nota, 
        colour = grupo)
    ) + 
  geom_boxplot(
    show.legend = F
    ) + 
  labs(
    x = "Grupo",
    y = "Nota"
  ) + 
  scale_x_discrete(
    labels = c("Leitor", "Não leitor")
  )
```

## O que os dados da pesquisa fictícia sugerem?

```{r}
pesquisa_fic |> 
  summarise(
    Média = mean(nota),
    .by = grupo
  ) |> 
  arrange(Média) |> 
  mutate(
    "Diferença entre as médias" = Média - lag(Média)
  ) |> 
  rename(
    Grupo = grupo
  ) |> 
  gt() |> 
  fmt_number(
    decimals = 2
  ) |> 
  cols_align(
    align = "center"  
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  sub_missing(
    missing_text = "-"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Delineamento entre participantes: dois grupos em condições diferentes

```{r}
#| eval: false
colchete <- image_read("img/curly-brackets-left.png")

image_rotate(colchete,degrees = 180) |> 
  image_write(path = "img/curly-brackets-right.png", format = "png")
```

![](img/teste-t-grupo-leitor.png){.absolute width="100" top="350" left="0"} ![](img/teste-t-grupo-nao-leitor.png){.absolute width="100" top="350" right="0"} ![](img/curly-brackets-left){.absolute width="100" top="350" left="85"} ![](img/curly-brackets-right.png){.absolute width="100" top="350" right="85"} ![](img/linha-vertical.png){.absolute width="200" top="200" right="450"} ![](img/pesquisadora-negra-sozinha.png){.absolute width="100" top="250" left="180"} ![](img/pesquisadora-cabelo-loiro-sozinha.png){.absolute width="100" top="450" left="250"} ![](img/pesquisador-indigena-sozinho.png){.absolute width="100" top="270" left="370"} ![](img/pesquisador-cabelo-preto-sozinho.png){.absolute width="100" top="250" right="180"} ![](img/pesquisador-asiatico-sozinho.png){.absolute width="100" top="450" right="250"} ![](img/pesquisadora-cabelo-preto-sozinha.png){.absolute width="100" top="270" right="370"}

::: {.absolute style="top: 450px; left: 0px; width: 250px; text-align: center; font-weight: bold; font-size: 22px;"}
Grupo leitor
:::

::: {.absolute style="top: 450px; right: 0; width: 250px; text-align: center; font-weight: bold; font-size: 22px;"}
Grupo não Leitor
:::

## Teste t para Amostras Independentes

-   Finalidade: examina se existe uma diferença estatisticamente significativa entre as médias de uma variável quantitativa em dois grupos independentes
-   Aplicação: ideal para delineamentos entre participantes. Por exemplo:
    -   Comparar níveis de ansiedade entre pessoas com e sem filhos
    -   Comparar a pressão sanguínea entre quem usa um medicamento e um grupo controle
    -   Comparar o estresse entre praticantes de atividades físicas e sedentários

## Teste t para Amostras Independentes

-   As Hipóteses (em um teste bidirecional):
    -   Hipótese Nula ($H_0$): afirma que não há diferença entre as médias dos grupos na população
        -   $H_0: \mu_a = \mu_b$
        -   $H_0: \mu_a - \mu_b = 0$
    -   Hipótese Alternativa ($H_1$): afirma que existe uma diferença entre as médias
        -   $H_1: \mu_a \neq \mu_a$
        -   $H_1: \mu_a - \mu_a \neq 0$

## Visualização da Hipótese Alternativa (H1)

```{r}
set.seed(234)

grupo_experimental <- rtruncnorm(
  n = 10000, a = 0, b = 100, 
  mean = 80, sd = 10
  )

grupo_controle <- rtruncnorm(
  n = 10000, a = 0, b = 100, 
  mean = 30, sd = 10
  )

grupos <- rep(c("Experimental", "Controle"), each = 10000)

hipotese_alternativa <- tibble(
  medida = c(grupo_experimental, grupo_controle),
  Grupo = grupos
)
```

```{r}
medias_alternativa <- hipotese_alternativa |> 
  summarise(
    m = mean(medida),
    .by = Grupo
  )

m_exp <- medias_alternativa[[1, 2]] 
m_ctrl <- medias_alternativa[[2, 2]]
```

```{r}
#| out-width: "70%"

hipotese_alternativa |> 
  ggplot(
    aes(x = medida, fill = Grupo),
  ) + 
  geom_density(
    alpha = 0.6, color = "white"
    ) + 
  geom_vline(
    xintercept = m_exp, linetype = 2,
    color = "blue"
  ) + 
  geom_vline(
    xintercept = m_ctrl, linetype = 2,
    color = "blue"
  ) + 
  geom_segment(
    x = m_ctrl, xend = m_exp, 
    y = 1400, yend = 1400,
    linetype = 2,
    color = "red"
  ) + 
  labs(
    title = "As populações de onde as amostras foram retiradas \ntêm médias diferentes",
    x = "Medida da Variável de Interesse",
    y = "Densidade (Probabilidade Relativa)",
    fill = "Grupo"
  ) +
  scale_fill_manual(
    values = c("Experimental" = "#0072B2", 
               "Controle" = "#D55E00")
  ) +
  theme(legend.position = "bottom")
  
```

## Visualização da Hipótese Nula (H0)

```{r}
set.seed(234)

grupo_experimental <- rtruncnorm(
  n = 1000, a = 0, b = 100, 
  mean = 80, sd = 10
  )

grupo_controle <- rtruncnorm(
  n = 1000, a = 0, b = 100, 
  mean = 79, sd = 10
  )

grupos <- rep(c("Experimental", "Controle"), each = 1000)

hipotese_nula <- tibble(
  medida = c(grupo_experimental, grupo_controle),
  Grupo = grupos
)
```

```{r}
medias_nula <- hipotese_nula |> 
  summarise(
    m = mean(medida),
    .by = Grupo
  )

m_exp <- medias_nula[[1, 2]] 
m_ctrl <- medias_nula[[2, 2]]
```

```{r}
#| out-width: "70%"

hipotese_nula |> 
  ggplot(
    aes(x = medida, fill = Grupo),
    ) + 
  geom_density(
    alpha = 0.6, color = "white"
    ) +
  geom_vline(
    xintercept = m_exp, linetype = 2,
    color = "blue"
      ) + 
  geom_vline(
    xintercept = m_ctrl, linetype = 2,
    color = "blue"
  ) + 
  geom_segment(
    x = m_ctrl, xend = m_exp, 
    y = 1400, yend = 1400,
    linetype = 2,
    color = "red"
    ) + 
  labs(
    title = "As populações de onde as amostras foram retiradas \ntêm médias quase iguais",
    x = "Medida da Variável de Interesse",
    y = "Densidade (Probabilidade Relativa)",
    fill = "Grupo"
  ) +
  scale_fill_manual(
    values = c("Experimental" = "#0072B2", 
               "Controle" = "#D55E00")
    ) + 
  theme(legend.position = "bottom")
```

## Teste t para Amostras Independentes

-   A Regra de Decisão (usando o p-valor):
    -   Se p ≤ 0,05: Rejeitamos a Hipótese Nula. A diferença observada é estatisticamente significativa
    -   Se p \> 0,05: Falhamos em rejeitar a Hipótese Nula. Não há evidência suficiente para afirmar que existe uma diferença

## Pressupostos do Teste T para amostras independentes {.smaller}

-   Variável Independente (VI): deve ser categórica com dois níveis (dicotômica)
-   Variável Dependente (VD): Deve ser escalar ou intervalar.
    -   A decisão sobre os tipos de variáveis é feita no desenho do estudo, guiada pela pergunta de pesquisa!
-   Independência das observações: os grupos devem ser mutuamente exclusivos (um participante não pode estar em ambos os grupos)
-   Verificação de outliers: o teste é sensível a valores atípicos. É importante inspecionar os dados para identificá-los e tratá-los, se for caso
-   Os dados da VD em cada grupo devem ser provenientes de uma população com distribuição aproximadamente normal
-   Homogeneidade das Variâncias (Homocedasticidade): as variâncias da VD devem ser aproximadamente iguais entre os grupos

# Avaliação dos pressupostos na pesquisa fictícia

## VI categórica e dicotômica

![](img/teste-t-grupo-leitor.png){.absolute width="300" top="170" left="0"} ![](img/linha-vertical.png){.absolute width="200" down="300" right="450"} ![](img/teste-t-grupo-nao-leitor.png){.absolute width="300" top="170" right="0"}

::: {.absolute style="top: 480px; left: 0px; width: 250px; text-align: center; font-weight: bold; font-size: 32px;"}
Grupo leitor
:::

::: {.absolute style="top: 480px; right: 25px; width: 250px; text-align: center; font-weight: bold; font-size: 32px;"}
Grupo não Leitor
:::

## VD escalar ou intervalar

```{r}
set.seed(789)

pesquisa_fic |> 
  slice_sample(n = 5)  |> 
  select(Nota = nota) |> 
  mutate(
    Aluno = letters[seq( from = 1, to = 5)],
    Aluno = str_c("Aluno ", Aluno),
    Texto = rep("Nota", 5)
  ) |> 
  pivot_wider(
    names_from = Aluno, values_from = Nota, id_cols = "Texto") |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |> 
  cols_label(
    Texto = " "
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
    ) 
```

## As observações devem ser independentes

O que há de errado nessa tabela?

```{r}
set.seed(90)

pesquisa_fic |> 
  group_by(grupo) |> 
  slice_sample(n = 3) |> 
  ungroup() |> 
  mutate(
    Aluno = c("Pedro", "Joana", "Tércia",
              "João", "José", "Joana")
    ) |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |> 
  cols_label(
    nota = "Nota",
    grupo = "Grupo"
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
    )
```

## As observações devem ser independentes

O que há de errado nessa tabela?

```{r}
set.seed(90)

pesquisa_fic |> 
  group_by(grupo) |> 
  slice_sample(n = 3) |> 
  ungroup() |> 
  mutate(
    Aluno = c("Pedro", "Joana", "Tércia",
              "João", "José", "Joana")
  ) |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |> 
  cols_label(
    nota = "Nota",
    grupo = "Grupo"
  ) |> 
  tab_style(
    style = list(
      cell_fill(color = "red"),
      cell_text(color = "white")
      ),
    locations = cells_body(columns = everything(), rows = c(2,6))
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Análise de outliers

```{r}
#| out-width: "70%"
pesquisa_fic |> 
  mutate(
    nota = case_when(nota == 9.9 ~ 15,
                     .default = nota)
  ) |> 
  ggplot(
    aes(nota), 
  ) + 
  geom_boxplot(
    color = "#569BBD"
    ) + 
  coord_flip()
```

## Distribuição normal da VD em cada grupo: gráfico Q-Q

```{r}
pesquisa_fic |> 
  ggplot(
    aes(sample = nota)
    ) + 
  stat_qq(
    aes(color = grupo), alpha = 0.8, 
    show.legend = FALSE
    ) + 
  stat_qq_line(
    color = "black", linetype = "dashed"
  ) + 
  labs(
    subtitle = "Distribuição normal: pontos que seguem de perto a linha diagonal",
    x = "Quantis Teóricos (da Distribuição Normal)",
    y = "Quantis da Amostra (Notas)"
  ) + 
  facet_wrap(vars(grupo))
```

## Distribuição normal da VD em cada grupo: teste de Shapiro-Wilk

-   Hipóteses:
    -   $H_0$: a variável de interesse é oriunda de uma população com distribuição normal
    -   $H_a$: a variável de interesse não é oriunda de uma população com distribuição normal

```{r}
pesquisa_fic |> 
  group_by(grupo) |> 
  shapiro_test(nota) |> 
  select(-variable) |> 
  rename(
    W = statistic
  ) |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |> 
  tab_spanner(
    label = "Shapiro-Wilk",
    columns = c(W, p)
  ) |> 
  fmt_number(
    decimals = 3
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Homogeneidade de variâncias: gráfico de caixas

```{r}
pesquisa_fic |> 
  ggplot(
    aes(x = grupo, y = nota, color = grupo)
    ) +
  geom_boxplot(
    show.legend = FALSE
    ) +
  labs(
    subtitle = "As alturas das caixas são semelhantes, sugerindo variâncias homogêneas.",
    x = "Grupo",
    y = "Nota na Avaliação"
  )
```

## Homogeneidade de variâncias: teste de Levene

-   Hipóteses:
    -   $H_0$: As variâncias populacionais são iguais entre os grupos
    -   $H_a$: As variâncias populacionais não são iguais entre os grupos

```{r}
pesquisa_fic |> 
  levene_test(nota ~ grupo, center = "mean") |> 
  relocate(
    statistic, .before = 1
  ) |> 
  rename(
    "F" = statistic
  ) |> 
  mutate(
    nota = "Nota", 
    .before = 1
  ) |> 
  gt() |> 
  cols_align(
    align = "center"  
 ) |>
  cols_label(
    nota = " " 
  ) |> 
  fmt_number(
    decimals = 3,
    columns = p
  ) |>
  fmt_number(
    decimals = 2,
    columns = "F"
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

# Análise e redação dos resultados para a pesquisa fictícia

## Teste T

```{r}
teste_t_pesquisa_fic <- 
  pesquisa_fic |> 
  t_test(
    nota ~ grupo, 
    var.equal = T, 
    comparisons = c("leitor", "não leitor"), detailed = T
  )

var_combinada <- pesquisa_fic |> 
  summarise(
    n = n(),
    var = var(nota),
    .by = grupo
  ) 
  
n1 <- var_combinada[[1, 2]]
n2 <- var_combinada[[2, 2]]
var1 <- var_combinada[[1, 3]]
var2 <- var_combinada[[2, 3]]
var_combinada <- ((n1 - 1)*var1 + (n2 - 1)*var2)/(n1 + n2 - 2)
ep_dif_medias <- sqrt(var_combinada*(1/n1 + 1/n2))

teste_t_pesquisa_fic <- teste_t_pesquisa_fic |> 
  mutate(
    "Diferença média" = estimate1 - estimate2,
    "Erro padrão da diferença" = ep_dif_medias
  ) |> 
  select(.y., method, "Estatística" = statistic, 
         gl = df, p, "Erro padrão da diferença",
         "Diferença média", "Limite inferior" = conf.low, 
         "Limite superior" = conf.high) |> 
  mutate(
    p = "< .001" 
  )
```

```{r}
teste_t_pesquisa_fic |>
  gt() |> 
  cols_align(
    align = "center"  
  ) |>
  cols_label(
    .y. = " ",
    method = " "
  ) |> 
  tab_spanner(
    label = "Intervalo de Confiança a 95%",
    columns = c("Limite inferior", "Limite superior")
  ) |> 
  fmt_number(
    decimals = 3,
    columns = p
  ) |>
  fmt_number(
    decimals = 2
  ) |> 
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Tamanho de efeito: D de Cohen

```{r}
set.seed(234)

d_de_cohen <- pesquisa_fic |> 
  cohens_d(
    formula = nota ~ grupo,  
    ref.group = "leitor", 
    var.equal = T, ci = T
  )
```

```{r}
d_de_cohen |> 
  select(
    "Dimensão do efeito" = effsize,
    "Limite inferior" = conf.low,
    "Limite superior" = conf.high,
    "Magnitude" = magnitude
  ) |> 
  mutate(
    teste = "d de Cohen",
    "Magnitude" = "Grande"
  ) |> 
  relocate(
    teste,
    .before = 1
  ) |> 
  gt() |> 
  cols_align(
    align = "center"  
  ) |>
  cols_label(
    teste = " "
  ) |> 
  tab_spanner(
    label = "Intervalo de Confiança a 95%",
    columns = c("Limite inferior", "Limite superior")
  ) |> 
  fmt_number(
    decimals = 3,
  ) |>
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Para que serve o Tamanho de Efeito? {.smaller}

Imagine dois estudos que testam uma nova terapia para ansiedade:

-   Estudo A: Usa uma escala de 0 a 10. A diferença entre os grupos foi de 2 pontos

-   Estudo B: Usa uma escala de 0 a 100. A diferença entre os grupos também foi de 2 pontos

Pergunta: O efeito da terapia foi o mesmo nos dois estudos?

> A diferença "bruta" não tem significado sem um padrão. Precisamos de uma forma de medir o tamanho do efeito que seja comparável entre estudos.

## O que é o d de Cohen?

É uma medida padronizada do tamanho do efeito que responde à pergunta:

> "Quão grande é a diferença entre as médias de dois grupos, se usarmos o desvio padrão como nossa unidade de medida?"

Ele transforma a diferença em uma unidade universal, permitindo a comparação e a interpretação da magnitude do efeito

## Entendendo o d de Cohen com uma Analogia {.smaller}

Podemos pensar no cálculo de uma forma bem simples:

-   A Diferença entre as Médias $M_1 - M_2$
    -   É a distância que queremos medir
-   O Desvio Padrão Combinado $(s_p)$
    -   É a nossa régua. Representa a variabilidade "típica" dos dados
-   O d de Cohen
    -   É a medição final: quantas vezes a nossa "régua" (desvio padrão) cabe na "distância" (diferença entre as médias)

## A Fórmula desmistificada {.smaller}

A fórmula matemática reflete exatamente a analogia da régua:

$$ 
d = \dfrac{M_1 - M_2}{s_p}
$$

Ou seja:

$$
d = \frac{\text{Distância entre as Médias}}{\text{A nossa 'Régua' (Desvio Padrão)}}
$$

## O que significa o resultado? (Regras de Bolso)[^2] {.smaller}

[^2]: O contexto da pesquisa é crucial! Um efeito "pequeno" pode ser clinicamente muito importante

As convenções de Cohen (1988) nos ajudam a ter um ponto de partida para a interpretação:

-   d ≈ 0.2 (Efeito Pequeno):
    -   A diferença é pequena. As distribuições dos grupos se sobrepõem muito.
-   d ≈ 0.5 (Efeito Médio):
    -   A diferença é moderada e visível a olho nu.
-   d ≈ 0.8 (Efeito Grande):
    -   A diferença é grande. Há pouca sobreposição entre as distribuições dos grupos.

## Visualização do d de Cohen

[![](img/qrcode_ddecohen.png){fig-alt="QR-code para o link https://rpsychologist.com/cohend/" fig-align="center"}](https://rpsychologist.com/cohend/)

## d de Cohen vs. p-valor

Eles não são inimigos, são parceiros! Eles respondem a perguntas diferentes e complementares

```{r}
comparacao <- tibble::tibble(
  Categoria = c("Pergunta que responde", "Função", "O que nos diz"),
  `p valor` = c("Existe uma diferença?", 
                "Significância Estatística", 
                "Se o efeito é \"real\" (não devido ao acaso)"),
  `d de Cohen` = c("Quão GRANDE é a diferença?", 
                   "Significância Prática / Clínica", 
                   "A magnitude do efeito no mundo real")
)
```

```{r}
comparacao |> 
  gt() |> 
  cols_align(
    align = "center", 
    columns = c("p valor", "d de Cohen")  
  ) |>
  cols_label(
    Categoria = " "
  ) |>
  tab_options(
    table.width = pct(100),
    table.font.size = "26px"
  ) |> 
  opt_stylize(
    style = 1, color = "gray"
  )
```

## Redação do Método

<center>
**Método**
</center>

**Procedimentos**

***Análise de Dados***

Um teste t para amostras independentes foi realizado para comparar a nota de alunos que separados em dois grupos: aqueles que liam os textos antes das aulas e aqueles que não tinha esse hábido. Foram avaliados os pressupostos de normalidade (teste de Shapiro-Wilk) e de homogeneidade das variâncias (teste de Levene).

## Redação dos Resultados {.smaller}

<center>
**Resultados**
</center>

O teste de Shapiro-Wilk não indicou desvios significativos da normalidade para o grupo de alunos leitores (W = 0.991, p = 0.958), nem para o grupo de alunos não leitores (W = 0.99, p = 0.953). O teste de Levene também não mostrou diferença significativa nas variâncias entre os grupos, (F(1, 96) = 1.95, p = 0.166). Os resultados indicaram uma diferença estatisticamente significativa entre as médias dos dois grupos, t(96) = 4.22, p \< .001. Alunos leitores (n = 50, M = 7.91, DP = 0.96) apresentaram um desempenho melhor do que os não leitores (n = 48, M = 6.98, DP = 1.21). A diferença média foi de 0.93 pontos (IC 95% \[0.49, 1.37\]). O tamanho de efeito foi grande (d = 0.853, IC 95% \[0.44, 1.32\] ). Esses resultados sugerem que ler os textos antes das aulas influencia no desempenho dos discentes nas avaliações.

# Violação de pressupostos: homogeneidade de variâncias

## Pesquisa fictícia 2

-   Pergunta de partida:
    -   Qual é o efeito do hábito de ler dos textos antes das aulas sobre as médias de ansiedade frente a provas discentes do curso de psicologia antes das avaliações?
        -   Grupo de leitores X Grupo de não leitores
        
        
## Hipóteses {.smaller}

-   Hipótese nula: não há diferença entre as médias das notas dos dois grupos
    -   $H_0: \mu_{leitores} = \mu_{não-leitores}$
-   Hipótese alternativa ($H_1$): há uma diferença entre as médias das notas dos dois grupos
    -   $H_1: \mu_{leitores} \neq \mu_{não-leitores}$
    

## Exemplo {.smaller}

-   Há diferença no consumo de combustível (`mpg`) entre carros com motores em V e retos (`vs`)?

## Manipulação dos dados {.smaller}

::: panel-tabset
### Ações

-   Carregar o conjunto de dados mtcars: `data("mtcars")`
-   Converter os rótulos das linhas para uma coluna: `rownames_to_column()`
-   Transformar em tibble para melhorar a visualização: `as_tibble()`
-   Recodficar a variável independente (`vs`) para facilitar a interpretação dos resultados
-   Transformar a variável independente em fator: `as_factor()`
-   Selecionar e salvar as variáveis que serão utilizadas em um novo objeto para facilitar a visualização: `select()`

### Código

```{r}
#| echo: true
# Carregar os dados
data("mtcars") 

dados_teste_t <- mtcars |>
  rownames_to_column(var = "modelo") |> # <1>
  as_tibble() |> # <2>
  mutate(
    vs = case_when( 
      vs == 0 ~ "V", .default = "reto" #<3>
    ),
    vs = as_factor(vs), #<4>
  ) |> 
  select(modelo, mpg, vs) #<5> 
```

1.  Converter os rótulos das linhas
2.  Transformar em tibble
3.  Recodficar a variável independente\
4.  Transformar em fator
5.  Selecionar as variáveis

### Resultado

```{r}
#| echo: true
dados_teste_t
```
:::

## Exploração dos dados {.smaller}

::: panel-tabset
### Tabela

```{r}
#| echo: true
descritivos_grupos <- dados_teste_t |> 
  summarise(
    n = n(),
    m = mean(mpg), 
    sd = sd(mpg),
    .by = vs
  ) |> 
  mutate(
    diferenca = m - lag(m)
    )

descritivos_grupos
```

### Gráfico

```{r}
#| echo: true
#| out-width: 50%
dados_teste_t |> 
  ggplot(
    aes(vs, mpg)
    ) +
  geom_boxplot(
    color = "#569BBD"
    ) +
  stat_boxplot(
    geom = 'errorbar', color = "#569BBD"
    )
```
:::

## Avaliação de pressupostos

-   Independência entre os grupos
-   Normalidade
-   Homogeneidade das variâncias

## Independência entre os grupos {.smaller}

-   As observações em cada grupo devem ser independentes entre si
-   Não deve haver relação ou influência entre as observações dos grupos "V" e "reto"

## Independência entre os grupos {.smaller}

-   Cada linha representa um veículo distinto; não há veículos repetidos (32 modelos, 32 linhas)

```{r}
#| echo: true
n_distinct(dados_teste_t$modelo)
nrow(dados_teste_t)
```

-   Cada modelo participa somente de um grupo

```{r}
#| echo: true
dados_teste_t |> 
  count(vs, modelo) |> 
  distinct(vs, n)
```

## Normalidade: teste de Shapiro-Wilk

-   Hipóteses:
    -   $H_0$: a variável de interesse é oriunda de uma população com distribuição normal
    -   $H_a$: a variável de interesse não é oriunda de uma população com distribuição normal
-   Avaliar a normalidade da VD (`mgp`) para cada grupo da VI (`vs`):
    -   "V" e "reto"

## Normalidade: `rstatix::shapiro_test()`

::: panel-tabset
### Uso

```{r}
#| echo: true
#| eval: false
shapiro_test(
  data, 
  ..., 
  vars = NULL
)
```

### Argumentos

-   **data**: um banco de dados. Colunas são variáveis.
-   **vars**: vetor de caracteres opcional contendo nomes de variáveis. Ignorado quando dot vars são especificados.
:::

## Normalidade: `rstatix::shapiro_test()`

```{r}
#| echo: true
resultado_shapiro <- dados_teste_t |> 
  group_by(vs) |> 
  shapiro_test(mpg)

resultado_shapiro
```

## Passo-a-passo do código

```{r}
#| echo: true
#| eval: false
dados_teste_t |> 
  # Agrupar pela VI
  group_by(vs) |> 
  # Indicar a VD a ser analisada
  shapiro_test(mpg)
```

## Homogeneidade de Variâncias: teste de Levene

-   Hipóteses:
    -   $H_0$: As variâncias populacionais são iguais entre os grupos
    -   $H_a$: As variâncias populacionais não são iguais entre os grupos
-   Avaliar a homogeneidade de variâncias da VD (`mpg`) entre os grupos da VI (`vs`):
    -   "V" e "reto"

## Homogeneidade de Variâncias: `rstatix::levene_test()`

:::: panel-tabset
### Uso

```{r}
#| echo: true
#| eval: false
levene_test(
  data, 
  formula, 
  center = median
)
```

### Argumentos

::: {style="font-size: 16pt;"}
-   **data**: um banco de dados para avaliar a fórmula ou um modelo.
-   **formula**: uma fórmula.
-   **center**: o nome de uma função para calcular o centro de cada grupo; "mean" (média) fornece o teste de Levene original; o padrão, "median" (mediana), fornece um teste mais robusto.
:::
::::

## Homogeneidade de Variâncias: `rstatix::levene_test()`

```{r}
#| echo: true
resultado_levene <- dados_teste_t |> 
  levene_test(formula =  mpg ~ vs, center = "mean")

resultado_levene
```

## Teste t para amostras independentes

-   Hipóteses (Bilateral):
    -   Hipótese nula: a média do consumo de combustível dos carros com motores em V é igual à média dos carros com motores retos $$H_0: \mu_{\text{V}} = \mu_{\text{reto}}$$
    -   Hipótese alternativa: a média do consumo de combustível dos carros com motores em V é diferente da média dos carros com motores retos $$H_a: \mu_{\text{V}} \ne \mu_{\text{reto}}$$

## Teste t para amostras independentes: `rstatix::t_test()`

:::: panel-tabset
### Uso

```{r}
#| echo: true
#| eval: false
t_test(
  data,
  formula,
  ref.group = NULL,
  var.equal = FALSE,
  alternative = "two.sided",
  conf.level = 0.95,
  detailed = FALSE
)
```

### Argumentos

::: {style="font-size: 14pt;"}
-   **data**: um banco de dados contendo as variáveis na fórmula.
-   **formula**: uma fórmula com a variável de resposta à esquerda e a explicativa à direita.
-   **ref.group**: uma sequência de caracteres especificando o grupo de referência.
-   **var.equal**: uma variável lógica indicando se deve tratar as duas variâncias como sendo iguais. Se TRUE, então a variância combinada é usada para estimar a variância, caso contrário, a aproximação de Welch (ou Satterthwaite) para os graus de liberdade é usada.
-   **alternative**: sequência de caracteres que fornece a direção da hipótese alternativa. As opções são "two-sided" (padrão), "greater" ou "less". Você pode especificar a letra inicial.
-   **conf_level**: um valor numérico entre 0 e 1. O valor padrão é 0.95.
-   **detailed**: valor lógico. O padrão é FALSE. Se TRUE, um resultado detalhado é mostrado.
:::
::::

## Teste t para amostras independentes: `rstatix::t_test()`

```{r}
#| echo: true
resultado_teste_t <- dados_teste_t |> 
  t_test(
    formula = mpg ~ vs, ref.group = "reto",
    var.equal = T, alternative = "two.sided", 
    detailed = T
  )

resultado_teste_t
```

## Tamanho de efeito: `rstatix::cohens_d()`

:::: panel-tabset
### Uso

```{r}
#| echo: true
#| eval: false
cohens_d(
  data,
  formula,
  ref.group = NULL,
  var.equal = FALSE,
  ci = FALSE,
)
```

### Argumentos

::: {style="font-size: 16pt;"}
-   **data**: um banco de dados contendo as variáveis na fórmula.
-   **formula**: uma fórmula com a variável de resposta à esquerda e a explicativa à direita.
-   **ref.group**: uma sequência de caracteres especificando o grupo de referência.
-   **var.equal**: uma variável lógica indicando se deve tratar as duas variâncias como sendo iguais. Se TRUE, então a variância combinada é usada para estimar a variância, caso contrário, a aproximação de Welch (ou Satterthwaite) para os graus de liberdade é usada.
-   **ci**: se TRUE, retorna os intervalos de confiança por bootstrap.
:::
::::

## Tamanho de efeito: `rstatix::cohens_d()`

```{r}
#| echo: true
set.seed(123)
resultado_cohens_d <- dados_teste_t |> 
  cohens_d(
  mpg ~ vs, ref.group = "reto",
  var.equal = T, ci = T
)

resultado_cohens_d
```

# Redação do método e dos resultados

## Método {.smaller}

**Procedimentos**

***Análise de Dados***

Um teste t para amostras independentes foi realizado para comparar o consumo de combustível entre carros com motores retos e motores em V. Foram avaliados os pressupostos de normalidade (teste de Shapiro-Wilk) e de homogeneidade das variâncias (teste de Levene).

## Resultados {.smaller}

```{r}
#| label: resultados-shapiro
w_s_teste_v <- resultado_shapiro[[1, "statistic"]] |> round(2)
p_s_teste_v <- resultado_shapiro[[1, "p"]] |> round(2)
w_s_teste_r <- resultado_shapiro[[2, "statistic"]]  |> round(2)
p_s_teste_r <- resultado_shapiro[[2, "p"]] |> round(2)
```

```{r}
#| label: resultados-levene
df_levene <- resultado_levene$df1
df_res_levene <- resultado_levene$df2
levene_f <- resultado_levene$statistic |> round(2)
levene_p <- resultado_levene$p |> round(2)
```

```{r}
#| label: resultados-descritivos
n_V <- descritivos_grupos[descritivos_grupos$vs == "V", "n"]
n_V <- pull(n_V)
m_V <- descritivos_grupos[descritivos_grupos$vs == "V", "m"]
m_V <- pull(m_V)
m_V <- round(m_V, 2)
sd_V <- descritivos_grupos[descritivos_grupos$vs == "V", "sd"]
sd_V <- pull(sd_V)
sd_V <- round(sd_V, 2)
n_reto <- descritivos_grupos[descritivos_grupos$vs == "reto", "n"]
n_reto <- pull(n_reto)
m_reto <- descritivos_grupos[descritivos_grupos$vs == "reto", "m"]
m_reto <- pull(m_reto)
m_reto <- round(m_reto, 2)
sd_reto <- descritivos_grupos[descritivos_grupos$vs == "reto", "sd"]
sd_reto <- pull(sd_reto)
sd_reto <- round(sd_reto, 2)
diferenca <- descritivos_grupos[[2, "diferenca"]]
diferenca <- round(diferenca, 2)
```

```{r}
#| label: resultados-teste-t
t_df <- resultado_teste_t[[1, "df"]]
statistic <- resultado_teste_t[[1, "statistic"]] |> round(2)
lower_ci <- resultado_teste_t[[1, "conf.low"]] |> round(2)
upper_ci <- resultado_teste_t[[1, "conf.high"]] |> round(2)
```

```{r}
#| label: resultados-cohens-d
d_valor <- resultado_cohens_d[[1, "effsize"]] |> round(2)
ci_low <- resultado_cohens_d[[1, "conf.low"]] |> round(2)
ci_high <- resultado_cohens_d[[1, "conf.high"]] |> round(2)
```

O teste de Shapiro-Wilk não indicou desvios significativos da normalidade para o grupo com motores em V (*W* = `r w_s_teste_v`, *p* = `r p_s_teste_v`), nem para o grupo com motores retos (*W* = `r w_s_teste_r`, *p* = `r p_s_teste_r`). O teste de Levene também não mostrou diferença significativa nas variâncias entre os grupos, (*F*(`r df_levene`, `r df_res_levene`) = `r levene_f`, *p* = `r levene_p`). Os resultados indicaram uma diferença estatisticamente significativa entre as médias dos dois grupos, *t*(`r t_df`) = `r statistic`, *p* \< .001. Carros com motores retos (n = `r n_reto`, M = `r m_reto`, DP = `r sd_reto`) apresentaram um desempenho melhor do que aqueles com motores em V (n = `r n_V`, M = `r m_V`, DP = `r sd_V`). A diferença média foi de `r diferenca` milhas por galão (IC 95% \[`r lower_ci`, `r upper_ci`\]). O tamanho de efeito foi grande (d = `r d_valor`, IC 95% \[`r ci_low`, `r ci_high`\] ). Esses resultados sugerem que o formato do motor influencia o consumo de combustível.

# Violação de pressupostos: homogeneidade de variâncias {style="font-size: 22pt;"}

## Exemplo {.smaller}

-   Há diferença no consumo de combustível (`mpg`) entre carros com motores de 4 e 6 cilindros (`cyl`)?

## Manipulação dos dados {.smaller}

::: panel-tabset
### Ações

-   Carregar o conjunto de dados mtcars: `data("mtcars")`
-   Converter os rótulos das linhas para uma coluna: `rownames_to_column()`
-   Transformar em tibble para melhorar a visualização: `as_tibble()`
-   Filtrar a variável independente (`cyl`) para que o banco contenha somente as categorias que serão utilizadas (4 e 6): `filter()`
-   Transformar a variável independente em fator: `as_factor()`
-   Selecionar e salvar as variáveis que serão utilizadas em um novo objeto para facilitar a visualização: `select()`

### Código

```{r}
#| echo: true
# Carregar os dados
data("mtcars") 

dados_teste_t <- mtcars |>
  # Converter os rótulos das linhas
  rownames_to_column(var = "modelo") |> 
  # Transformar em tibble
  as_tibble() |>
  # Filtrar as categorias utilizads
  filter(cyl %in% c(4, 6)) |> 
  mutate(
    # Transformar em fator
    cyl = as_factor(cyl) 
  ) |> 
  # Selecionar as variáveis
  select(modelo, mpg, cyl) 
```

### Resultado

```{r}
#| echo: true
dados_teste_t
```
:::

## Exploração dos dados {.smaller}

::: panel-tabset
### Tabela

```{r}
#| echo: true
descritivos_grupos <- dados_teste_t |> 
  summarise(
    n = n(),
    m = mean(mpg), 
    sd = sd(mpg),
    .by = cyl
  ) |> 
  mutate(
    diferenca = m - lag(m)
    )

descritivos_grupos
```

### Gráfico

```{r}
#| echo: true
#| out-width: 50%
dados_teste_t |> 
  ggplot(
    aes(cyl, mpg)
    ) +
  geom_boxplot(
    color = "#569BBD"
    ) +
  stat_boxplot(
    geom = 'errorbar', color = "#569BBD"
    )
```
:::

## Avaliação de pressupostos

-   Normalidade
-   Homogeneidade das variâncias

## Normalidade: `rstatix::shapiro_test()`

```{r}
#| echo: true
resultado_shapiro <- dados_teste_t |> 
  group_by(cyl) |> 
  shapiro_test(mpg)

resultado_shapiro
```

## Homogeneidade de Variâncias: `rstatix::levene_test()`

```{r}
#| echo: true
resultado_levene <- dados_teste_t |> 
  levene_test(formula =  mpg ~ cyl, center = "mean")

resultado_levene
```

## Teste t para amostras independentes (variâncias diferentes): `rstatix::t_test()` {.smaller}

```{r}
#| echo: true
resultado_teste_t <- dados_teste_t |> 
  t_test(
    formula = mpg ~ cyl, ref.group = "4",
    var.equal = F, alternative = "two.sided", 
    detailed = T
  )

resultado_teste_t
```

## Tamanho de efeito: `rstatix::cohens_d()`

```{r}
#| echo: true
set.seed(123)
resultado_cohens_d <- dados_teste_t |> 
  cohens_d(
  mpg ~ cyl, ref.group = "4",
  var.equal = F, ci = T
)

resultado_cohens_d
```

# Redação do método e dos resultados

## [Método]{style="text-align: center;"} {.smaller}

**Procedimentos**

***Análise de Dados***

Um teste t para amostras independentes foi realizado para comparar o consumo de combustível entre carros com motores de 4 e 6 cilindros. Foram avaliados os pressupostos de normalidade (teste de Shapiro-Wilk) e homogeneidade das variâncias (teste de Levene).

## [Resultados]{style="text-align: center;"} {.smaller}

```{r}
w_s_teste_4 <- resultado_shapiro[[1, "statistic"]] |> round(2)
p_s_teste_4 <- resultado_shapiro[[1, "p"]] |> round(2)
w_s_teste_6 <- resultado_shapiro[[2, "statistic"]]  |> round(2)
p_s_teste_6 <- resultado_shapiro[[2, "p"]] |> round(2)
```

```{r}
df_levene <- resultado_levene$df1
df_res_levene <- resultado_levene$df2
levene_f <- resultado_levene$statistic |> round(2)
levene_p <- resultado_levene$p |> round(3)
```

```{r}
n_6 <- descritivos_grupos[descritivos_grupos$cyl == "6", "n"]
n_6 <- pull(n_6)
m_6 <- descritivos_grupos[descritivos_grupos$cyl == "6", "m"]
m_6 <- pull(m_6)
m_6 <- round(m_6, 2)
sd_6 <- descritivos_grupos[descritivos_grupos$cyl == "6", "sd"]
sd_6 <- pull(sd_6)
sd_6 <- round(sd_6, 2)
n_4 <- descritivos_grupos[descritivos_grupos$cyl == "4", "n"]
n_4 <- pull(n_4)
m_4 <- descritivos_grupos[descritivos_grupos$cyl == "4", "m"]
m_4 <- pull(m_4)
m_4 <- round(m_4, 2)
sd_4 <- descritivos_grupos[descritivos_grupos$cyl == "4", "sd"]
sd_4 <- pull(sd_4)
sd_4 <- round(sd_4, 2)
diferenca <- descritivos_grupos[[2, "diferenca"]]
diferenca <- round(diferenca, 2)
```

```{r}
t_df <- resultado_teste_t[[1, "df"]] |> round(0)
statistic <- resultado_teste_t[[1, "statistic"]] |> round(2)
lower_ci <- resultado_teste_t[[1, "conf.low"]] |> round(2)
upper_ci <- resultado_teste_t[[1, "conf.high"]] |> round(2)
```

```{r}
d_valor <- resultado_cohens_d[[1, "effsize"]] |> round(2)
ci_low <- resultado_cohens_d[[1, "conf.low"]] |> round(2)
ci_high <- resultado_cohens_d[[1, "conf.high"]] |> round(2)
```

O teste de Shapiro-Wilk não indicou desvios significativos da normalidade para o grupo com motores de 4 cilindros (*W* = `r w_s_teste_4`, *p* = `r p_s_teste_4`), nem para o grupo com motores de 6 cilindros (*W* = `r w_s_teste_6`, *p* = `r p_s_teste_6`). O teste de Levene mostrou que não havia homogeneidade na variância entre os grupos, (*F*(`r df_levene`, `r df_res_levene`) = `r levene_f`, *p* = `r levene_p`). Diante da violação deste pressuposto, foi realizado o teste t de Welch (ou teste t de variâncias desiguais). Os resultados indicaram uma diferença estatisticamente significativa entre as médias dos dois grupos, *t*(`r t_df`) = `r statistic`, *p* \< .001. Carros com motores de 4 cilindros (n = `r n_4`, M = `r m_4`, DP = `r sd_4`) apresentaram um desempenho melhor do que aqueles com motores de 6 cilindros (n = `r n_6`, M = `r m_6`, DP = `r sd_6`). A diferença média foi de `r diferenca` milhas por galão (IC 95% \[`r lower_ci`, `r upper_ci`\]). O tamanho de efeito foi grande (d = `r d_valor`, IC 95% \[`r ci_low`, `r ci_high`\] ). Esses resultados sugerem que o número de cilindros do motor influencia o consumo de combustível.
